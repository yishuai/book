---
layout: post
title: Spark 简介
---

本节首先介绍 Spark，解释为什么 Spark 的 Map Reduce 计算比 Hadoop 的快，然后介绍 Spark 的生态。

## Spark 简介

Spark 是用 Scala 语言编写的。Scala 是一种函数式的编程语言。它编程像写函数似的，写很多lambda函数，所以就特别适合做大数据。因为就像我们学习 Map Reduce 程序时看到的，大数据处理程序的编写，主要就是写作 Map 和 Reduce 函数，而大数据平台的运行，就是送这些函数进去。所以，用 Scala 写大数据处理框架，非常合适。

Spark 本身也确实写得很好，然后，在 Spark 上面，大家又开发了很多工具，比如各种机器学习、推荐算法、图分析的算法，后面又加上 streaming 实时流处理，当数据源源不断地来时，它也能处理。所以它现在用的很广。

相对于 Hadoop，Spark 最大的特点是：运算速度快很多，而需要的节点数少很多。它的运算速度快，是因为它是基于内存的，而 Hadoop 的 Map Reduce 是基于硬盘的。因为计算速度快，所以同样的工作、耗时，它需要的节点数就少很多。比如，同样的 100T 数据，Spark 只需要 1/10 的节点，1/3 的运算时间。Spark 需要的节点数少，会带来很多好处，因为节点数越少就越好管理。比如，你在这里摆 2000 台机器，和你在这里摆 200 台机器，你要的运维管理人员、空调数，完全是不一样的。所以现在大家如果在实验室要装的话，老师肯定让你装 Spark。有个七八台机器，就是一个挺好的 Spark 集群了。

那么，为什么 Spark 基于内存计算，就能快很多呢？我们看下面的大数据存储的性能模型，即不同存储单元的读取速度：

- 本机 DRAM 和 Disk
	- Memory：100ns，20GB/s
	- Disk：10ms，200MB/s
- 本机架 DRAM 和 Disk
	- Memory：300us，100MB/s
	- Disk：11ms，100MB/s
- 非本机架、集群 DRAM 和 Disk
	- Memory：500us，10MB/s
	- Disk：12ms，10MB/s

我们下面来解读这些数据。

首先，大数据的存储结构，有一个基本的层级。离 CPU 最近的存储是 L1 和 L2 两级缓存。它们俩都在 CPU 里头。这些缓存很小，我们编程一般用不到它们。然后，我们能用的是本地内存（DRAM），就是本机的内存条。然后我们可以读本地的硬盘。

如上面的数据所示，如果我们读本机内存的话，每秒钟能够读 20G 字节。你看现在一个 4K 的电影，也不过 20G，它一秒钟就传完了，是这种速度的感觉。但如果你读硬盘的话，每秒钟只能读 200M 字节，速度降了 100 倍。但每秒读 200M 字节的速度其实已经很快了，对不对？你用 USB 2.0 的 U 盘复制一个文件，速度一般是每秒 60M 字节。

好，如果你读本机架上的其他机器的内存或者硬盘，这个速度又一下就降下来了。你看，一下就降到 100M 字节每秒了。如果你再去读另外一个机架上的硬盘或者内存，速度又一下就降下来了。你看才 10M 字节每秒。所以这就是我们为什么要避免去读别的机器上的数据的原因。

所以，当我们用本机的 CPU 计算的时候，最快的方式是读本机内存里的数据就最好了。所以 SPARK 它就这么做。它是基于内存的。因为读内存比读本地硬盘快 100 倍，比读别的机器上的硬盘或者内存要快 1000 倍，所以 Spark 是最快的。这就是为什么 SPARK 这么快的原因。

## Spark 生态

Spark 也是开源的，因此，自从它出现以后，也像 Hadoop 那样，像滚雪球那样，迅速地发展了起来，构建起了一个完整的生态。

Spark 的生态非常强大，包括：

- Streaming 流式处理：就是每来一个窗口的数据，它就能立刻工作，实时地进行处理
- MLlib 机器学习库：基本的回归、分类算法都能做，还有推荐算法
- GraphX 图算法库：包括 PageRank 等

这就是对 Spark 的一个基本的介绍。

<br/>

|[Index](../) | [Previous](0-spark) | [Next](3-rdd) |
