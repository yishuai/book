---
layout: post
title: Flink
---

Flink 是一个功能强大的“流数据”的处理平台，在商业、金融领域有广泛的应用。比如阿里巴巴、 CaptialOne 就用了很多 Flink。我们前面看的职位中就提到：有 Flink 开发经验的优先。所以非常值得学习。

Flink 以逐“事件”的方式处理流数据。这一点和 Spark 的 Streaming 处理不同。Spark 的 Streaming，是基于窗口的 Streaming，比如积累两分钟的内容，然后就来处理一次。但 Flink 是来一个事件就可以立刻处理的。所以，更加实时。当然，它也支持基于窗口的处理、批处理。

Flink 是按照事件发生的时间先后顺序进行处理，而不是按照数据接收的时间先后进行处理。所以这一点很适合商业和金融，因为它们强调时间的先后顺序。

Flink 能够接入各种数据源。它有很多连接器， Source 和 Sink 都可以接入 HDFS，kafka，文本等。然后它有各种变换（Transformation）功能，如转换、统计。

我们最后介绍一个 Flink 实验：利用 Flume 监视，将出现的日志数据，送入 Kafka 后，由 Flink 收到，进行店铺商品销售额的统计和排序，然后把排名前 5 的门店结果存入 MySQL。淘宝双 11 的时候，你看到淘宝的屏幕上不断显示销售额的变化，就是这么做的。

<br/>

|[Index](../) | [Previous](11-3-flume) |
