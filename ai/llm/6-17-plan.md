---
layout: post
title: 计划
---

## 论文

### LeCun 论文

Reacting vs planning (Yann LeCun)

- Towards Machines That Can Understand, Reason, & Plan， [Video](https://www.youtube.com/watch?v=_JfEScYyVCE)

- A Path Towards Autonomous Machine Intelligence，[论文](https://openreview.net/pdf?id=BZ5a1r-kVsf)，[视频](https://youtu.be/OKkEdTchsiE?si=61T7QHOqJF0VyAzR)

- Problem of LLM，[Twitter 1](https://www.linkedin.com/posts/yann-lecun_my-unwavering-opinion-on-current-auto-regressive-activity-7030921081876029443-8F6j)

- Plan [Twitter 2](https://www.linkedin.com/posts/yann-lecun_please-ignore-the-deluge-of-complete-nonsense-activity-7133900073117061121-tTmG)

### Agent Planning 相关论文

Plan formulation
- [2023/11] JARVIS-1: Open-world Multi-task Agents with Memory-Augmented Multimodal Language Models. ZiHao Wang (Peking University) et al. arXiv. [paper] [code]
- [2023/10] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. Andy Zhou (University of Illinois Urbana-Champaign) et al. arXiv. [paper] [project page] [code]
- [2023/05] Tree of Thoughts: Deliberate Problem Solving with Large Language Models. Shunyu Yao (Princeton University) et al. arXiv. [paper] [code]
- [2023/05] Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. Yue Wu (Carnegie Mellon University) et al. arXiv. [paper]
- [2023/05] Reasoning with Language Model is Planning with World Model. Shibo Hao (UC San Diego) et al. arXiv. [paper] [code]
- [2023/05] SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks. Bill Yuchen Lin (Allen Institute for Artificial Intelligence) et al. arXiv. [paper] [code]
- [2023/04] LLM+P: Empowering Large Language Models with Optimal Planning Proficiency. Bo Liu (University of Texas at Austin) et al. arXiv. [paper] [code]
- [2023/03] HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. Yongliang Shen (Microsoft Research Asia) et al. arXiv. [paper] [code]
- [2023/02] Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents. ZiHao Wang (Peking University) et al. arXiv. [paper] [code]
- [2022/05] Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. Denny Zhou (Google Research) et al. arXiv. [paper]
- [2022/05] MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning. Ehud Karpas (AI21 Labs) et al. arXiv. [paper]
- [2022/04] Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. Michael Ahn (Robotics at Google) et al. arXiv. [paper]
- [2023/05] Agents: An Open-source Framework for Autonomous Language Agents. Wangchunshu Zhou (AIWaves) et al. arXiv. [paper] [code]
- [2022/12] Don’t Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments. Yu Gu (The Ohio State University) et al. ACL. [paper] [code]

Plan reflection
- [2023/11] JARVIS-1: Open-world Multi-task Agents with Memory-Augmented Multimodal Language Models. ZiHao Wang (Peking University) et al. arXiv. [paper] [code]
- [2023/10] Chain-of-Verification Reduces Hallucination in Large Language Models. Shehzaad Dhuliawala (Meta AI & ETH Zu ̈rich) et al. arXiv. [paper]
- [2023/10] FireAct: Toward Language Agent Fine-tuning. Baian Chen (System2 Research) et al. arXiv. [paper] [project page] [code] [dataset]
- [2023/08] SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning. Ning Miao (University of Oxford) et al. arXiv. [paper] [code]
- [2023/05] ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models. Zhipeng Chen (Renmin University of China) et al. arXiv. [paper] [code]
- [2023/05] Voyager: An Open-Ended Embodied Agent with Large Language Models. Guanzhi Wang (NVIDIA) et al. arXiv. [paper] [project page] [code]
- [2023/03] Chat with the Environment: Interactive Multimodal Perception Using Large Language Models. Xufeng Zhao (University Hamburg) et al. arXiv. [paper] [code]
- [2022/12] LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. Chan Hee Song (The Ohio State University) et al. arXiv. [paper] [code]
- [2022/10] ReAct: Synergizing Reasoning and Acting in Language Models. Shunyu Yao (Princeton University) et al. arXiv. [paper] [code]
- [2022/07] Inner Monologue: Embodied Reasoning through Planning with Language Models. Wenlong Huang (Robotics at Google) et al. arXiv. [paper] [code]
- [2021/10] AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts. Tongshuang Wu (University of Washington) et al. arXiv. [paper]

<br/>

| [Index](./) | [Previous](6-13-reasoning) | [Next](6-21-innovation)
