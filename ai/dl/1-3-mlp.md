---
layout: post
title: 深度神经元网络
---

本节深度学习的基本单元。首先学习“感知机”和“Logistic 回归”这两个机器学习的经典模型，然后基于它们，介绍前向神经元网络。

## 感知机

人工智能的起源是“感知机”。1958 年，Rosenblatt 参考人脑神经元的信号处理方式，提出了“感知机”模型。该模型很简单，如下图所示：

![](fig/perceptron.png)

如上图所示，感知机的输出会对输入做线性加权和，然后通过一个“阶跃”（Step）函数，输出结果 0 或 1。所以，它能做 0/1 分类的工作，比如：判断一个邮件是不是垃圾邮件。

感知机的缺陷也很明显。首先，它对输入信号的处理是“线性加权”，所以，它是一个线性模型。其次，它的输出非常简单，非 0 即 1，这限制了它的应用。

## Logistic 回归

Logistic 回归是一个非常常用的机器学习模型。它也是对输入 x 做线性加权，然后输出。

作为一个分类模型，Logistic 回归的输出不是感知机的“阶跃”函数，而是一个 Logistic 函数。这有两个好处：

首先，这让 Logistic 回归可以输出类别的“概率”。Logistic 函数的输出是在 0 到 1 之间的一个数字。这样的一个数字正适合表示“概率”，所以，Logistic 回归实际上输出的是一个概率，比如：一封邮件是垃圾邮件的概率。这是它的一个好处：它的输出可以表示概率。

其次，这让 Logistic 模型很方便进行优化。这是因为Logistic 函数是“可微”的，因此我们就可以计算它的梯度，然后基于这个梯度进行优化。而感知机的“阶跃”函数不是可微的。

除了采用 Logistic 函数作为输出，它还引入了“交叉熵”作为 Loss。“交叉熵”能够衡量两个概率分布的距离（即 KL Divergence）。通过简单的数学变换，我们可以发现，LR 模型的交叉熵 Loss 对参数 w 的梯度，很容易计算：它等于（模型结果 - 真实值）* x。这让模型的优化变得很简单。

上面这些特点让 Logistic 回归成为一个适合大规模数据优化的强有力的模型。请大家在工作中注意使用它来解决实际问题。上面这些特点也被用于了神经元网络。我们下面就介绍神经元网络模型。

## 前向神经元网络

最简单的神经元网络模型是前向神经元网络。它由很多神经元组成。每个神经元像感知机那样，也是把输入 x 做线性加权和，但是然后它会对这个和进行非线性变换，比如 tanh、sigmoid、ReLU 等常用的变换。

前向神经元网络包括很多“层”。每层都并列很多神经元。然后前一层的输出，送入下一层的输入。这样连起来很多层，就构成“深度”神经元网络。通过引入非线性激活函数和构造很深的神经元网络，神经元网络获得了对非线性数据的强大模型能力。

神经元网络在进行多元分类任务时，引入了 Softmax 输出各个类型的概率。它也采用交叉熵作为 Loss。Softmax 和交叉熵一起，很容易计算梯度。

## 课本：

- Dive in Deep Learning，[4. Linear Neural Networks for Classification](https://d2l.ai/chapter_linear-classification/index.html)
- SLP 课本
  - 第 5 章：Logistic 回归
  - 第 7 章：神经元网络
- AI4All Model - Neural Network PPT

## 课程材料

- 斯坦福大学 CS224n
  - Logistic 回归 PPT
  - 神经元网络 PPT
- MIT 深度学习 Lec 1 PPT

## Logistic 回归（LR）复习题

- 为什么说 Logistic 回归 是 Discriminative 分类器？ 写出其优化目标函数的数学表达式，然后解释
- 写出 LR 模型的数学表达式，解释其物理意义
- （案例分析题）给定一段文本，请设计对其进行情感分类的特征
- 写出 0/1 分类问题 的 交叉熵 （Cross-Entropy）Loss 函数 的 数学表达式
- 推导 LR 模型下， Cross-Entropy Loss 的 梯度。要求给出推导过程。给出推导结果的物理意义

<br/>

|[Index](./) | [Previous](0-3-material) | [Next] (1-5-train)
