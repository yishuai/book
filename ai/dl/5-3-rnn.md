---
layout: post
title: 深度序列模型
---

我们下面学习 RNN 模型的原理、设计和优化，包括LSTM、解码输入的方法。

世界充满了序列信息：视频、语言模型、时间序列。我们理解它们的方式，是“循环（Recurrence）式”的，比如，我们看一个字的时候，不是把它单拿出来，只读它的意思，而是会基于前面看过的字的内容，获得对这个字的理解。这就是“Recurrence”的，即：利用先前发生过的事件、获得的知识，推理后面的事件。

### 应用场景

深度序列模型应用有三种主要场景。它们采用的模型形式如下：
- Many to One（文本分类）
    - RNN 编码器
- One to Many（文本生成、图像文字描述）
    - RNN 解码器
- Many to Many（翻译）
    - Seq2Seq

在实践中，序列模型的应用非常广泛，比如语言模型，它能预测下一个单词。还有条件语言模型 Seq2Seq，它包括编码器和解码器。

### RNN

RNN 模型的特点是“自环”（Loops），即：神经元的输出，会回到它的输入，参与新的输入的处理。通过这种方法，它能让先前输入的信息，帮助未来输入的信息的处理，这就允许了历史信息会被利用。

RNN 的代码实现其实非常简单。下面是用 numpy 对其的实现：

![RNN ](fig/rnn-code.png)

如上图所示，它的代码其实不复杂。指定好输入输出之后，就可以了。

### RNN BPTT 梯度计算

RNN 的 BPTT 梯度计算比较神奇。这是因为 RNN 的同一套模型参数，在它循环计算的过程中，被多次用到了。结果是：以 $$s$$ 为隐状态，观察它对 w 的导数 $$ R = ds/dw $$，我们能够以一种“循环”的形式，计算每一步的梯度，计算公式如下

$$
 R_t = A(B + W^T R_{t-1})
$$

这就是说：这个导数 $$R$$ 是循环的。具体的推导，请学习课本《Mining Massive Dataset》的第 13 章中的 Many-to-Many 的计算过程。

上面这种循环计算梯度的过程，会给 RNN 的训练带来“梯度爆炸”和“梯度消失”的问题。具体来说，如果使用 tanh 激活函数，loss 对 w 的导数可能会很小，因此，这样循环计算后，梯度会消失；而如果使用其它激活函数，loss 对 w 的导数可能很大或者很小，导致梯度爆炸或者消失。

因此，在实际系统中，RNN 的工作很不稳定，并不常用。

### LSTM

在实际系统中常用的循环神经元网络模型是 LSTM。它能够解决 RNN 的梯度爆炸和梯度消失的问题。

观察上面的公式，我们可以发现，为了解决 RNN 的梯度爆炸和梯度消失的问题，我们需要每一级模型对隐状态 s 的变换函数 q 对 s 的梯度 dq/ds 约等于 1。s 是隐状态，即激活函数的输出。这样的话，即使我们迭代很多次，它也不会爆炸或者消失。

LSTM 就满足上面这个需求。它具体是这么实现的：

首先，它有两个状态。一个状态是 cell memory a：每一步改变不大，管长期记忆；另一个状态是隐状态 h：每一步改变大，管短期记忆。

其次，LSTM 引入几个“门”来控制这些状态的更新。这些门即 sigmoid 函数：它们的输出值为 0-1。然后它们和要控制的值做乘法，0 就相当于 门全部关闭；1 就相当于门全部打开。这包括：

cell memory 的变化，由“遗忘门”和“输入门”控制。这两个门由输入 x 和隐状态 h，做 tanh ( w*h + x ) 获得。

在这两个门的作用下，cell memory a 会以“滑动平均”的方式，逐渐“遗忘”老信息，加入新的输入信息。因此，它的变化很平缓，是一种长期 memory。这就意味着它的梯度接近 1，所以不会梯度爆炸或消失。

在这一点上，LSTM 有点像 ResNet 的 Skip 连接。ResNet 也是通过 Skip 连接，让模块的梯度约等于 1，避免了梯度爆炸和消失的问题。

然后，cell memory 不直接输出。它做一个 tanh ，得到 h，然后 通过 h 再得到 cell 的输出。然后，我们也有一个“输出门”，控制 h 的输出。

这就和 RNN 有本质的区别：RNN 的 h 既做输出，又做存储，因此 h 会被 w 乘。然后，因为“循环”，所以会梯度爆炸或者消失。

### RNN 做实际训练中的问题

在 RNN 的实际训练中，有一个“自回归模型的分布漂移问题”，即：我们在做模型训练的时候，会把训练数据中的“真实”单词，送进模型，获得下一个单词。但在测试的时候，“自回归模型”产生的单词是由模型产生的，因此，输入模型的单词，也是模型上一步输出的单词。那么，这些模型产生的单词的分布，和训练时用的真实数据中的单词的分布可能不一样。这样就导致训练和测试的数据，并不匹配，很可能导致模型性能恶化。

为了缓解这个“分布漂移”的问题，人们提出了在训练时，逐渐增加后者（输入模型输出的单词）的概率的方法，这就是所谓的“Scheduled Sampling”方法。

此外，在实际模型的构建中，一般通过堆叠 RNN 的编码器、解码器，构造双向 RNN，从而让信息可以双向流动，获得更好的性能。比如语音识别，就可以通过这种方法，用后面的音素来帮忙识别前面的音素。

在生成序列时，通常会用 Beam Search 的解码方法，通过容忍多个可能的输出，最后选择一个合适的序列。

## 课本

- Dive in Deep Learning
  - [9. Recurrent Neural Networks](https://d2l.ai/chapter_recurrent-neural-networks/index.html)
  - [10. Modern Recurrent Neural Networks](https://d2l.ai/chapter_recurrent-modern/index.html)

- Mining Massive Dataset，Ch.13, Neural Network and Deep Learning

## 课程材料

- 伯克利 RNN PPT
- MIT RNN PPT
- AI4All Model - RNN Transformer PPT

<br/>

|[Index](./) | [Previous](3-5-vis) | [Next] (5-5-attention)
