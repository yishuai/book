---
layout: post
title: HDFS
---

本节介绍 Hadoop 分布式文件存储（HDFS）。如果我们的数据特别大，一个电脑存不下，这时就需要存到很多台电脑上。HDFS 就是帮我们完成这项工作的。

## 工作机制

我们首先介绍 HDFS 的工作机制。它包括两方面：

1）分块机制：HDFS 会把大文件切成一个个 128 兆的块，然后存到不同的机器上。这样的话，我们就可以用多个机器，同时访问不同的块。这就是并行访问，能够提高访问速度。

2）多副本机制：HDFS 会将每个块，复制多份，分别存到不同的电脑上。这样的话，当一台机器因为故障，无法访问存在它上面的块时，我们可以访问别的机器上的副本。这就是容错。HDFS 有一个机制，就是当它发现一个机器宕了，导致一些块访问不了了，它就会在别的机器上赶紧把这些块再复制一个。这样的话，就总是保持一个块在系统中有足够多的块。

## 架构

我们然后介绍它的架构。HDFS 中的电脑，我们一般称它们为“节点”。HDFS 有两种节点。一种节点是 DataNode，另一种节点叫做 NameNode。

顾名思义，DataNode 就是存数据（Data）的。而 NameNode 它是管理你存在文件系统中的文件的“名字”（Name）的。具体来说，当你访问存在其中的一个文件时，你要告诉它这个文件的路径。这个路径就是这个文件的“名字”。NameNode 拿到了这个名字，就会查自己的数据库，告诉你这个文件的数据块都存在哪几个数据节点上。这样你就可以去这些 DataNode 上去取。

因此，HDFS 工作的过程是这样的：你告诉 NameNode 这个文件的路径，它就告诉你这个文件被切成了多少块、存在哪些 DataNode 上。然后，你就去 DataNode 去取。

显然，NameNode 是很关键的。所以这个 NameNode 一般有两个，它们是备份的。一旦一个 NameNode 坏了，另一个 NameNode 可以来撑住。

## HDFS 命令行工具

我们最后来看如何操作 HDFS。我们可以在终端窗口利用命令行工具进行操作。
因为我们是对 Hadoop 的 HDFS 操作，所以在命令前面要加 Hadoop 相关的语句。比如 

- hadoop fs -ls 是列出目录下的文件
- hadoop fs -mkdir 是创建一个目录
- pwd 是看当前的路径
- hadoop fs -copyFromLocal 是将本地文件复制到 HDFS 里
- hadoop fs -rm 是删除文件
- hadoop fs -rmdir 是删除目录

## 小结

Hadoop 分布式文件存储（HDFS）把大数据文件分成小块，这样就可以实现并行访问，提高访问速度；然后，它对每个小块都在多个机器上存储多个副本，这样就可以实现容错。也就是说：当一台机器出现故障，连不上的时候，可以访问另一个机器上的另外的副本。我们会简单介绍它的结构，说明它包括 Namenode 和 Datanode 两种节点。

<br/>

|[Index](../) | [Previous](2-job) | [Next](5-mapreduce) |
