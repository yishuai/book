---
layout: post
title: 后记
---

2024 年课程结束后，同学反馈。

## 贾梦茹

最重要的基础-编程。老师的课程告诉了我如何去思考，可以用什么样的手段以及如何选择更好的办法去解决问题，给我们搭架了很恢宏的高楼框架，但是地基是需要自己去打结实的，由于时间问题，老师课件中分享的关于python的课下练习完成了一部分，但是sql没有跟上，因此在做本次实验中遇到了很多编程上的问题，或许只是一点点小的逻辑或者语法问题，但是因为水平实在太低完全看不出来，也就无从下手改正，当然可以借助ai，但是ai并不是全能的，这只是一个辅助工具，我都不知道如何去向ai提问又谈何改正。

虽然课程结束了，但是，学无止境！

## 张振迪

通过这次综合性实验,我对大数据技术的应用有了初步了解和认识。作为一个大数据小白，虽然学习起来比较困难，但是我还是把所有实验任务完成了。

其中最令我印象深刻的是Flume实验，我实验过程中大部分时间也花在了这里，实验时要保持清醒头脑，知道每行代码的含义，一个小小的配置错误也会导致整个数据传输失败，但是思路并不是死板的，实现一个目的可以用多种方式，这让我深刻体会到了数据采集的复杂性和灵活性。

我对大数据技术的认识加深了，在进行之前的每个模块的单独实验时，我有时候不明白这些单独的实验任务在实际应用过程中是如何联系在一起的。但是通过综合实验，我对它们的联合应用有了初步的认识，这种系统设计和整合的能力,对于未来的工程实践十分重要。

最后感谢老师的认真讲解与授课，老师们让我学到了很多东西，《大数据技术基础及应用》这门课程打开了我的眼界，让我收获颇多！

祝老师们身体健康，工作顺利！

## 高啟

作为研究生的第一课，尤其又涉及我不擅⻓的编程，我原以为我接受起来会十分困难，但是实际的学习过程却出乎意料的轻松，愉快。这都源于老师提供的丰富课程学习资料以及课上通俗易懂的讲解，还有老师耐心的实验演示。

本次课程，我从零开始触及编程，再到结合老师的帮助一步步学习，最后能够解决实际的小问题。华为云课程实验使我对flume，kafka，flink，mysql，hdfs，hive等大数据应用上的名词有了清晰理解。通过实践实现了数据的存储与管理，包括流数据的处理、传输等。

通过本次课的学习，我不仅学到了有关大数据的很多知识，更重要的是锻炼了我的自学能力和独立解决问题的心境。

最后感谢老师的悉心讲解与教授，祝老师们身体健康，学术⻓⻘!

## 胥焱

通过大数据课程学习到了很多，受益匪浅。从课程中收获到用通义千问 GPT 进行交流问答，用 MarsCode 平台的 AI 辅助，给日常学习带来了极大的便 利。通过课程了解到一些企业的求职岗位，由此有了学习的目标，在每一模块 练习后的 AI 求职完善自己的专业简历，循序渐进的课程教学收获良多。

通过课程接触到华为企业提供的学习渠道，有所增长见识。通过实验指导书和老师辛勤录制的教学视频，在摸索中完成此次华为云实验的学习，然因能力不足，初次学习了解到数据科学的相关知识，在个别实验中操作不当，未能得到要求的实验结果，但也觉得这是一次很棒的学习体验，从零基础开始，通过实验指导书与 AI 交流，了解到系统的很多知识，逐步学习掌握了如何使用华为云的各项服务来构建一个完整的数据处理流水线。

起初，我对云计算的概念仅停留在理论层面，缺乏实际操作的经验。通过这次实践，我不仅深入了解了华为云的服务生态，还学会了如何利用这些服务来解决实际问题。

华为云实验也是一次通过课程学习到大数据系统原理，不仅掌握了 MapReduce、Zookeeper、Flink 和 Kafka 的基本操作，还学会了如何将它们结合起来构建一个完整的分布式数据处理系统。这些技术的应用让我对大数据处理有了更深刻的理解，也为我未来从事相关领域的工作奠定了坚实的基础。今后也将继续学习研究，并积极将理论与实践相结合，期待能收获更多的知识！

## 张雯萱

我是一名交通运输的学生，之前从没有接触过大数据的内容，因此做实验理解大数据各组件的语句对我来说比较困难，但听了老师上课对于大数据工程师的介绍，觉得这确实是一门很有用的工具，因此整个学习过程中很用心的学习大数据各部分内容，并做相应练习。

但是在进行华为云实验时还是感觉比较困难，一是因为对大数据平台各组件内容理解不透彻，对手册的步骤总是无法理解，在理解每个语句意思，了解实验意图后才能顺利进行实验；二是因为比较粗心，总是因为大小写、空格、路径修改问题导致执行报错，也总是会卡很长时间；三是因为做实验时间比较紧张，手册步骤较多导致做实验过程比较困难，在此也非常感谢老师、老师和各位同学对我的帮助，让我能较顺利的完成实验。

总体来看，此次实验过程我加深了对大数据平台各组件的理解，理解代码解决问题的能力也都有很大提高，但是对于一些高深的代码仍然理解不透彻，很多实验步骤也是简单的跟做，无法理解深意，希望后续有机会可以继续学习相关内容，真正将大数据的学习融入到自己的研究内容中。

## 林煜珠

作为一名交通运输规划与管理专业的博士生，我的研究方向是城市交通信号控制，并且我的研究需要处理80个交叉口的秒级的车辆数据。同时在大数据技术日益渗透交通行业的背景下，我对大数据产生了较为浓厚的兴趣，因此我选择了老师的《大数据技术基础》这门课程，并且在学习过程中收获颇丰。

起初，我对大数据的认识仅停留在表面的兴趣上，在新闻媒体中和朋友的谈论中听到过关于大数据这个领域和大数据工程师这个职业，然而也会有很多的疑问，比如大数据工程师的主要职责是什么，需要什么样的技术支撑，又面向什么样的应用场景？随着课程的深入，我逐渐明白大数据在各个行业及我所从事的交通信号控制中的巨大潜力。尤其是在处理大规模数据、进行实时分析以及优化交通控制策略方面，大数据技术在各个方面均展示了不可替代的优势。

通过老师课堂上的讲解，我学习到了大数据的基础知识，包括利用pandas、SQL等过滤、查询和计算数据，还学习了HDFS、MapReduce、Spark、Hive、Zookeeper以及Kafka等数据处理工具的特点、功能、工作机制以及应用场景和条件等。而老师讲解的面对数据进行的各种操作如聚合、清洗等知识也让我在面对茫茫海量数据之后有了自己的处理思路和处理方法。这些知识不仅拓展了我的视野，让我掌握了大数据处理基本技能，还为我的研究提供了强有力的技术支持。

在老师的细致讲解以及华为云实验的基本操作下，我对每一部分理论知识有了清晰的理解，并且对每一部分在我研究中的应用学习到了更多技能。例如，通过实验，我掌握了如何使用HDFS进行数据的存储和读取，这使得我可以高效地管理和处理交叉口信号与车辆数据；通过MapReduce编程实验，我学会了在分布式数据处理器中如何对数据进行处理；通过Spark实验，我掌握了如何进行实时数据处理，优化交通流量的预测模型；通过Hive实验，我学会了如何使用SQL对大规模数据进行复杂查询和分析，从而帮助我在研究中进行精确的数据分析和预测。

在学习过程中，我从基础的理论知识逐步深入到复杂的实际操作，对大数据技术的理解和应用能力得到了显著提升。特别是在处理数据的过程中，我逐渐掌握了各种数据处理工具的使用，并且对数据的处理流程变得更加熟练。这些技能不仅帮助我提高了面对TB级数据的研究效率，还让我在面对复杂数据时能够更加从容地进行分析和决策。

最后，感谢老师在课程中给予的指导和帮助。正是在老师的悉心教导下，我才能够在短时间内掌握如此多的大数据技术，并将其应用到我的研究中。这门课程不仅为我打开了大数据世界的大门，也为我未来的研究奠定了坚实的基础。这使得我对未来的工作和研究充满了信心，我相信，在大数据技术的支持下，我能够为交通规划与管理做出更大的贡献。

## 崔业康

通过这次综合实验，我深刻体会到了大数据生态系统的强大和复杂性。从数据采集、传输、存储到处理分析，每个环节都扮演着重要角色，彼此紧密协作，形成了一个完整的数据处理流水线。

首先，之前我对大数据相关的知识几乎一无所知，只接触过MATLAB这类传统的数据分析软件。这次实验让我接触到了Flume、Kafka、Flink、MySQL等多个大数据组件，开阔了眼界，也让我意识到大数据生态系统的广阔和复杂。我理解了它们在大数据架构中的定位和优势:Flume高效采集数据，Kafka实现高吞吐的消息队列，Flink进行实时流处理，HDFS提供可靠的分布式存储。这些组件相互配合，既保证了数据的实时性，又兼顾了数据的可靠性和可扩展性。

其次，这门课程对我来说是一次巨大的飞跃。我不仅提高了Python编程能力，还初步掌握了SQL等数据库知识，对大数据处理流程有了整体认识。从数据采集、传输、存储到实时处理和批处理，每个环节都让我获益匪浅。尤其是理解了各组件之间如何协同工作，这对构建完整的大数据平台至关重要。同时，我也完成了实时处理和批处理并行的设计，满足了不同场景下的数据分析需求。

最后，这个实验也让我认识到了在大数据领域持续学习的重要性。技术日新月异，只有不断实践和探索，才能真正掌握这些工具，并在实际项目中灵活运用。

这次综合实验不仅提升了我的技术能力，更重要的是培养了我解决复杂问题的思维方式。虽然我知道还有很长的路要走，但这次经历极大地激发了我对大数据领域的兴趣和热情。我深感自己在这个快速发展的领域中潜力无限，未来还有更多知识等待我去探索和掌握。总的来说，这门课程让我受益匪浅，为我未来在大数据领域的深入学习和发展奠定了坚实的基础。

## 梁程炬

在本次大数据综合实验中，我作为一名运输与物流专业的学生，起初对大数据技术几乎一无所知。然而，怀着对新知识的渴望，我毅然投身于这个充满挑战的学习过程。

在实验过程中，我面临了诸多困难。例如，在基于RDS的SQL实验以及DLV实验中，当尝试输入`createtablefull_tableasSELECTr.user_id,r.movie_id,r.rating,u.age,u.gender,u.occupation_idFROMratingsrjoinusersuonr.user_id=u.id`命令时，我无法选择数据库且无法创建表，经过排查发现是语法错误，最终通过去掉`createtablefull_tableas`部分解决了该问题。

在HDFS分布式文件系统实验中，进行HDFS的数据上载时，输入命令`Hdfsdfs-putu.data/haha/`和`Hdfsdfs-putu.item/haha/`时，总是无法上传，后来发现是语法中H应该小写的问题。在Mapreduce实验中，运行`pythonRatingsBreakdown.py-rhadoophdfs:///home/24115079/u.data`命令时，出现`Inputpathhdfs://home/24115079/u.datadoesnotexist!`的错误提示，通过在home目录下运行程序并加入`cd/home;ls;`两条语句得以解决。

在阅读Mapreduce的程序文件时，理解上存在困难，幸得豆包AI的帮助逐句理解代码。在Spark实验中，遇到了`UnicodeDecodeError:'utf-8'codeccan'tdecodebyte0xe9inposition2892:invalidcontinuationbyte`的报错，通过豆包AI的指导修改代码，将`loadMovieNames`函数中打开文件的编码指定为`ISO-8859-1`。还出现了`ModuleNotFoundError:Nomodulenamed'pyspark'`的错误，以及在创建消费者时遇到`new-consumerisnotarecognizedoption`的问题，后来通过调整命令和排查连接问题，发现可能是Kafka服务器未正常运行、网络问题或配置错误等原因导致无法与指定的Kafka服务器（192.168.0.205:9092）建立连接。

在Hive实验中，设备曾出现问题，但在修复后顺利完成了实验。在Zookeeper实验中，登陆zookeeper时无法连接ip，后来通过进入到bin的目录下（输入“cd/opt/client/ZooKeeper/zookeeper/bin”）解决了该问题。

在Kafka实验和Flume实验中，也遇到了创建消费者时无法与指定的Kafka服务器建立连接的问题，可能是由于Kafka服务器未正常运行、网络问题或配置错误等原因，还出现了内存不足的情况（如在创建Kafka主题时，出现`OpenJDK64-BitServerVMwarning:INFO:os::commit_memory(0x00000000f0000000,268435456,0)failed;error='Cannotallocatememory'(errno=12)`的错误）。

尽管在综合大实验中遇到了诸多困难，最终未能完全完成该实验，但通过这次作业，我的能力得到了显著增长。我不仅对大数据处理的流程和各个组件的作用有了更深入的理解，还提高了自己解决问题的能力和自学能力。在遇到问题时，我通过查阅资料、请教他人以及借助工具（如豆包AI）的帮助，努力寻找解决方案，这使我在技术学习和实践方面积累了宝贵的经验。虽然还有许多知识需要进一步学习和掌握，但我相信这次的经历为我未来在大数据领域的学习和发展奠定了坚实的基础。

## 张宪霖

本次实验学到了很多，上课没有听明白或者没有涉及到的地方都通过实验以及撰写实验报告弄明白了，收获不少，虽然不想写实验总结，但还是来养个好习惯吧。

<br/>

|[Index](../)|
